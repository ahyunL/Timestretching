# -*- coding: utf-8 -*-
"""tiny_test1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BzXcGsSnQ9jwX6_0oogWYswISL_psRGX

# Whisper-tiny test 1

##1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ë¡œë“œ
"""

!pip install -U transformers datasets torchaudio

!pip install -U transformers datasets huggingface_hub evaluate

"""### Hugging Face ë¡œê·¸ì¸"""

from huggingface_hub import notebook_login
notebook_login()

"""### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"""

from datasets import load_dataset, Audio, Dataset
from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer
from evaluate import load
import random
import torch

"""### ë°ì´í„°ì…‹ ìŠ¤íŠ¸ë¦¬ë° ë¡œë“œ"""

n_train = 200
n_val = 100
n_test = 100

langs = ["ko", "ja", "en", "de"]

train_data = []
val_data = []
test_data = []

for lang in langs:
    print(f"âœ… Loading {lang}...")

    train_data += list(load_dataset(
        "mozilla-foundation/common_voice_16_1", lang,
        split="train",
        streaming=True,
        trust_remote_code=True
    ).take(n_train))

    val_data += list(load_dataset(
        "mozilla-foundation/common_voice_16_1", lang,
        split="validation",
        streaming=True,
        trust_remote_code=True
    ).take(n_val))

    test_data += list(load_dataset(
        "mozilla-foundation/common_voice_16_1", lang,
        split="test",
        streaming=True,
        trust_remote_code=True
    ).take(n_test))

# ë°ì´í„° ì„ê¸°(ì…”í”Œ)
random.shuffle(train_data)
random.shuffle(val_data)
random.shuffle(test_data)

# Hugging Face Dataset ê°ì²´ë¡œ ë³€í™˜
train_dataset = Dataset.from_list(train_data)
val_dataset = Dataset.from_list(val_data)
test_dataset = Dataset.from_list(test_data)

"""##2. ë°ì´í„° ì „ì²˜ë¦¬


*   Whisper Tokenizer ì¤€ë¹„
*   í•™ìŠµ ë°ì´í„° í¬ë§· ë§ì¶”ê¸°

### Whisper PRocessor ì¤€ë¹„


*   Whisper ëª¨ë¸ ì‚¬ì „ í•™ìŠµ ì²´í¬í¬ì¸íŠ¸ì‚¬ìš©
*   Processor = FeatureExtractor + Tokenizer
* ì˜¤ë””ì˜¤ -> ì…ë ¥ íŠ¹ì§• ì¶”ì¶œ
* í…ìŠ¤íŠ¸ -> í† í°í™”
"""

model_checkpoint = "openai/whisper-tiny"

processor = WhisperProcessor.from_pretrained(model_checkpoint)
feature_extractor = processor.feature_extractor
tokenizer = processor.tokenizer

"""### ì˜¤ë””ì˜¤ ì»¬ëŸ¼ ìƒ˜í”Œë§ë ˆì´íŠ¸ì— ë§ì¶”ê¸°"""

train_dataset = train_dataset.cast_column("audio", Audio(sampling_rate=16000))
val_dataset = val_dataset.cast_column("audio", Audio(sampling_rate=16000))
test_dataset = test_dataset.cast_column("audio", Audio(sampling_rate=16000))

"""### ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜


*   ì˜¤ë””ì˜¤ -> Whisper ì…ë ¥ íŠ¹ì§• ì¶”ì¶œ
*   í…ìŠ¤íŠ¸ ë¬¸ì¥ -> Whisper í† í°í™”


*   í•™ìŠµ ë°ì´í„° ì¤€ë¹„




"""

def prepare_dataset(example):
    audio = example["audio"]
    example["input_features"] = processor.feature_extractor(
        audio["array"], sampling_rate=16000
    ).input_features[0]

    # âœ… ì¤‘ìš”: ë¦¬ìŠ¤íŠ¸ ìƒíƒœë¡œ ì €ì¥ (padding X, tensor ë³€í™˜ X)
    example["labels"] = processor.tokenizer(
        example["sentence"]
    ).input_ids

    return example

"""### ì „ì²˜ë¦¬ ë§¤í•‘


*   prepare_batchí•¨ìˆ˜ë¥¼ ëª¨ë“  ìƒ˜í”Œì— ì ìš©
*   í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ ì œê±°


"""

processed_dataset_train = train_dataset.map(
    prepare_dataset,
    remove_columns=[col for col in train_dataset.column_names if col not in ["locale"]]
)

processed_dataset_val = val_dataset.map(
    prepare_dataset,
    remove_columns=[col for col in val_dataset.column_names if col not in ["locale"]]
)

processed_dataset_test = test_dataset.map(
    prepare_dataset,
    remove_columns=[col for col in test_dataset.column_names if col not in ["locale"]]
)

"""### Torch í¬ë§·ìœ¼ë¡œ ë³€í™˜


*   Datasets -> Pytorch Tensor í˜•íƒœë¡œ ë³€í™˜
*   Trainerê°€ DataLoaderì²˜ëŸ¼ ì½ì„ ìˆ˜ ìˆê²Œ ì¤€ë¹„


"""

processed_dataset_train.set_format(columns=["input_features", "labels", "locale"])
processed_dataset_val.set_format(columns=["input_features", "labels", "locale"])
processed_dataset_test.set_format(columns=["input_features", "labels", "locale"])

"""##3. Whisper ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°

### ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°


*   openai/Whisper-tiny ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ
*   ì‚¬ì „í•™ìŠµëœ Whisperëª¨ë¸ -> Fine-tuning ì¤€ë¹„ ì™„ë£Œ
"""

model = WhisperForConditionalGeneration.from_pretrained(model_checkpoint)

from dataclasses import dataclass
from typing import Any, Dict, List, Union

@dataclass
class DataCollatorSpeechSeq2SeqWithPadding:
    processor: Any
    padding: Union[bool, str] = True

    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
        input_features = [{"input_features": f["input_features"]} for f in features]
        label_features = [{"input_ids": f["labels"]} for f in features]
        batch = self.processor.feature_extractor.pad(input_features, return_tensors="pt")
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")
        labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)
        batch["labels"] = labels
        return batch

data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)

"""### íŒŒë¼ë¯¸í„° ì„¸íŒ…


*   í•™ìŠµ ì¶œë ¥ ê²½ë¡œ ì§€ì •
*   ë°°ì¹˜ ì‚¬ì´ì¦ˆ, running rate, epochìˆ˜ ì„¤ì •
* fp16 ìë™ ì‚¬ìš©(ê°€ëŠ¥í•œ ê²½ìš°)


"""

from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./whisper-tiny-finetuned",
    per_device_train_batch_size=4,
    gradient_accumulation_steps=2,
    learning_rate=5e-5,
    num_train_epochs=3,
    logging_steps=10,
    save_steps=50,
    fp16=torch.cuda.is_available(),
    report_to="none"
)

"""### Trainer ì •ì˜


*   í•™ìŠµí•  ëª¨ë¸, íŒŒë¼ë¯¸í„° ì„¸íŒ…
*   í•™ìŠµìš©(train) / ê²€ì¦ìš©(eval) ë°ì´í„°ì…‹ ì§€ì •
* Whisper feature extractor -> ì…ë ¥ ì „ì²˜ë¦¬ ìë™ ì ìš©


"""

from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=processed_dataset_train,
    eval_dataset=processed_dataset_val,
    tokenizer=processor,
    data_collator=data_collator,
)

"""### í•™ìŠµ ì‹œì‘


*   í•­ëª© ì¶”ê°€
*   í•­ëª© ì¶”ê°€


"""

trainer.train()

"""### ëª¨ë¸ ì €ì¥"""

trainer.save_model("./whisper-tiny-finetuned")

"""### Processor ì €ì¥"""

# âœ… Whisper Processor (Tokenizer + FeatureExtractor)ë„ ê°™ì´ ì €ì¥
processor.save_pretrained("./whisper-tiny-finetuned")

"""##4. Test

### ì–¸ì–´ë³„ë¡œ Validation ë°ì´í„° ë‚˜ëˆ„ê¸°
"""

# âœ… ê° ì–¸ì–´ë³„ ê²€ì¦(validation) ë°ì´í„°ì…‹ í•„í„°ë§
val_ko = processed_dataset_val.filter(lambda x: x["locale"] == "ko")
val_en = processed_dataset_val.filter(lambda x: x["locale"] == "en")
val_ja = processed_dataset_val.filter(lambda x: x["locale"] == "ja")
val_de = processed_dataset_val.filter(lambda x: x["locale"] == "de")

"""### ì–¸ì–´ ë¦¬ìŠ¤íŠ¸ì™€ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ì¤€ë¹„"""

!pip install jiwer

from evaluate import load

lang_datasets = {
    "ko": val_ko,
    "en": val_en,
    "ja": val_ja,
    "de": val_de
}

wer_metric = load("wer")
cer_metric = load("cer")

lang_scores = {}

for lang, dataset in lang_datasets.items():
    print(f"\nğŸŒ Language: {lang.upper()}")

    # âœ… ì˜ˆì¸¡ ìƒì„±
    predictions_output = trainer.predict(dataset)

    # âœ… logits êº¼ë‚´ê¸° (tupleì—ì„œ)
    logits = predictions_output.predictions[0]

    # âœ… ë””ì½”ë”©
    decoded_preds = processor.tokenizer.batch_decode(
        logits.argmax(axis=-1),
        skip_special_tokens=True
    )
    decoded_labels = processor.tokenizer.batch_decode(
        predictions_output.label_ids,
        skip_special_tokens=True
    )

    # âœ… ì¼ë¶€ ê²°ê³¼ í™•ì¸
    for pred, label in zip(decoded_preds, decoded_labels):
        print(f"ğŸ”¹ Prediction: {pred}")
        print(f"ğŸ”¸ Reference : {label}")
        print("------")

    # âœ… í‰ê°€
    wer_score = wer_metric.compute(predictions=decoded_preds, references=decoded_labels)
    cer_score = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)

    lang_scores[lang] = {"WER": wer_score, "CER": cer_score}

    print(f"âœ… {lang.upper()} WER: {wer_score:.4f}")
    print(f"âœ… {lang.upper()} CER: {cer_score:.4f}")

print("\nâœ…âœ…âœ… Language-wise Evaluation Results âœ…âœ…âœ…")
for lang, scores in lang_scores.items():
    print(f"{lang.upper()} - WER: {scores['WER']:.4f} | CER: {scores['CER']:.4f}")
