# -*- coding: utf-8 -*-
"""tiny_test1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BzXcGsSnQ9jwX6_0oogWYswISL_psRGX

# Whisper-tiny test 1

##1. 데이터 불러오기

### 라이브러리 설치 및 로드
"""

!pip install -U transformers datasets torchaudio

!pip install -U transformers datasets huggingface_hub evaluate

"""### Hugging Face 로그인"""

from huggingface_hub import notebook_login
notebook_login()

"""### 라이브러리 임포트"""

from datasets import load_dataset, Audio, Dataset
from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer
from evaluate import load
import random
import torch

"""### 데이터셋 스트리밍 로드"""

n_train = 200
n_val = 100
n_test = 100

langs = ["ko", "ja", "en", "de"]

train_data = []
val_data = []
test_data = []

for lang in langs:
    print(f"✅ Loading {lang}...")

    train_data += list(load_dataset(
        "mozilla-foundation/common_voice_16_1", lang,
        split="train",
        streaming=True,
        trust_remote_code=True
    ).take(n_train))

    val_data += list(load_dataset(
        "mozilla-foundation/common_voice_16_1", lang,
        split="validation",
        streaming=True,
        trust_remote_code=True
    ).take(n_val))

    test_data += list(load_dataset(
        "mozilla-foundation/common_voice_16_1", lang,
        split="test",
        streaming=True,
        trust_remote_code=True
    ).take(n_test))

# 데이터 섞기(셔플)
random.shuffle(train_data)
random.shuffle(val_data)
random.shuffle(test_data)

# Hugging Face Dataset 객체로 변환
train_dataset = Dataset.from_list(train_data)
val_dataset = Dataset.from_list(val_data)
test_dataset = Dataset.from_list(test_data)

"""##2. 데이터 전처리


*   Whisper Tokenizer 준비
*   학습 데이터 포맷 맞추기

### Whisper PRocessor 준비


*   Whisper 모델 사전 학습 체크포인트사용
*   Processor = FeatureExtractor + Tokenizer
* 오디오 -> 입력 특징 추출
* 텍스트 -> 토큰화
"""

model_checkpoint = "openai/whisper-tiny"

processor = WhisperProcessor.from_pretrained(model_checkpoint)
feature_extractor = processor.feature_extractor
tokenizer = processor.tokenizer

"""### 오디오 컬럼 샘플링레이트에 맞추기"""

train_dataset = train_dataset.cast_column("audio", Audio(sampling_rate=16000))
val_dataset = val_dataset.cast_column("audio", Audio(sampling_rate=16000))
test_dataset = test_dataset.cast_column("audio", Audio(sampling_rate=16000))

"""### 전처리 함수 정의


*   오디오 -> Whisper 입력 특징 추출
*   텍스트 문장 -> Whisper 토큰화


*   학습 데이터 준비




"""

def prepare_dataset(example):
    audio = example["audio"]
    example["input_features"] = processor.feature_extractor(
        audio["array"], sampling_rate=16000
    ).input_features[0]

    # ✅ 중요: 리스트 상태로 저장 (padding X, tensor 변환 X)
    example["labels"] = processor.tokenizer(
        example["sentence"]
    ).input_ids

    return example

"""### 전처리 매핑


*   prepare_batch함수를 모든 샘플에 적용
*   필요없는 컬럼 제거


"""

processed_dataset_train = train_dataset.map(
    prepare_dataset,
    remove_columns=[col for col in train_dataset.column_names if col not in ["locale"]]
)

processed_dataset_val = val_dataset.map(
    prepare_dataset,
    remove_columns=[col for col in val_dataset.column_names if col not in ["locale"]]
)

processed_dataset_test = test_dataset.map(
    prepare_dataset,
    remove_columns=[col for col in test_dataset.column_names if col not in ["locale"]]
)

"""### Torch 포맷으로 변환


*   Datasets -> Pytorch Tensor 형태로 변환
*   Trainer가 DataLoader처럼 읽을 수 있게 준비


"""

processed_dataset_train.set_format(columns=["input_features", "labels", "locale"])
processed_dataset_val.set_format(columns=["input_features", "labels", "locale"])
processed_dataset_test.set_format(columns=["input_features", "labels", "locale"])

"""##3. Whisper 모델 불러오기

### 모델 불러오기


*   openai/Whisper-tiny 체크포인트에서 모델 로드
*   사전학습된 Whisper모델 -> Fine-tuning 준비 완료
"""

model = WhisperForConditionalGeneration.from_pretrained(model_checkpoint)

from dataclasses import dataclass
from typing import Any, Dict, List, Union

@dataclass
class DataCollatorSpeechSeq2SeqWithPadding:
    processor: Any
    padding: Union[bool, str] = True

    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
        input_features = [{"input_features": f["input_features"]} for f in features]
        label_features = [{"input_ids": f["labels"]} for f in features]
        batch = self.processor.feature_extractor.pad(input_features, return_tensors="pt")
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")
        labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)
        batch["labels"] = labels
        return batch

data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)

"""### 파라미터 세팅


*   학습 출력 경로 지정
*   배치 사이즈, running rate, epoch수 설정
* fp16 자동 사용(가능한 경우)


"""

from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./whisper-tiny-finetuned",
    per_device_train_batch_size=4,
    gradient_accumulation_steps=2,
    learning_rate=5e-5,
    num_train_epochs=3,
    logging_steps=10,
    save_steps=50,
    fp16=torch.cuda.is_available(),
    report_to="none"
)

"""### Trainer 정의


*   학습할 모델, 파라미터 세팅
*   학습용(train) / 검증용(eval) 데이터셋 지정
* Whisper feature extractor -> 입력 전처리 자동 적용


"""

from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=processed_dataset_train,
    eval_dataset=processed_dataset_val,
    tokenizer=processor,
    data_collator=data_collator,
)

"""### 학습 시작


*   항목 추가
*   항목 추가


"""

trainer.train()

"""### 모델 저장"""

trainer.save_model("./whisper-tiny-finetuned")

"""### Processor 저장"""

# ✅ Whisper Processor (Tokenizer + FeatureExtractor)도 같이 저장
processor.save_pretrained("./whisper-tiny-finetuned")

"""##4. Test

### 언어별로 Validation 데이터 나누기
"""

# ✅ 각 언어별 검증(validation) 데이터셋 필터링
val_ko = processed_dataset_val.filter(lambda x: x["locale"] == "ko")
val_en = processed_dataset_val.filter(lambda x: x["locale"] == "en")
val_ja = processed_dataset_val.filter(lambda x: x["locale"] == "ja")
val_de = processed_dataset_val.filter(lambda x: x["locale"] == "de")

"""### 언어 리스트와 매핑 딕셔너리 준비"""

!pip install jiwer

from evaluate import load

lang_datasets = {
    "ko": val_ko,
    "en": val_en,
    "ja": val_ja,
    "de": val_de
}

wer_metric = load("wer")
cer_metric = load("cer")

lang_scores = {}

for lang, dataset in lang_datasets.items():
    print(f"\n🌍 Language: {lang.upper()}")

    # ✅ 예측 생성
    predictions_output = trainer.predict(dataset)

    # ✅ logits 꺼내기 (tuple에서)
    logits = predictions_output.predictions[0]

    # ✅ 디코딩
    decoded_preds = processor.tokenizer.batch_decode(
        logits.argmax(axis=-1),
        skip_special_tokens=True
    )
    decoded_labels = processor.tokenizer.batch_decode(
        predictions_output.label_ids,
        skip_special_tokens=True
    )

    # ✅ 일부 결과 확인
    for pred, label in zip(decoded_preds, decoded_labels):
        print(f"🔹 Prediction: {pred}")
        print(f"🔸 Reference : {label}")
        print("------")

    # ✅ 평가
    wer_score = wer_metric.compute(predictions=decoded_preds, references=decoded_labels)
    cer_score = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)

    lang_scores[lang] = {"WER": wer_score, "CER": cer_score}

    print(f"✅ {lang.upper()} WER: {wer_score:.4f}")
    print(f"✅ {lang.upper()} CER: {cer_score:.4f}")

print("\n✅✅✅ Language-wise Evaluation Results ✅✅✅")
for lang, scores in lang_scores.items():
    print(f"{lang.upper()} - WER: {scores['WER']:.4f} | CER: {scores['CER']:.4f}")
